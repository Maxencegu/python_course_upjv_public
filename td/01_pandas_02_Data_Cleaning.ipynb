{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "# **Python for Data Science**\n",
        "\n",
        "### *Data Cleaning: Handling Missing Data (NA) and Cleaning Datasets*\n",
        "\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "6UqIO5ZN7hD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Introduction**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8QLZXk-K9WUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning and the proper handling of missing values (also called **NaN** or **NA**) are two essential steps before performing any analysis on a dataset.  \n",
        "\n",
        "The objective of this notebook is to go step by step through these cleaning operations in order to obtain a **clean and reliable DataFrame**.  \n",
        "Indeed, real-world datasets often contain issues such as missing values, duplicates, or inconsistent entries.  \n",
        "\n",
        "For this course, we will continue working with the **`transactions` DataFrame** that we imported in the previous exercise.\n"
      ],
      "metadata": {
        "id": "PXA6UO-w8G2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Loading and Inspecting the Dataset**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Import the `pandas` module as `pd` and load the file **`transactions.csv`** into a DataFrame named `transactions`.  \n",
        "The file uses semicolons (`;`) as separators, and the column containing the identifiers is `'transaction_id'`.  \n",
        "\n",
        "- (b) Display the first 10 rows of the DataFrame using the `.head()` method."
      ],
      "metadata": {
        "id": "cxueXsjV-SWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "vi-bKN4e-c70"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Cleaning a Dataset**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Wx72rTsmSgJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we introduce the main **DataFrame methods** that are useful for cleaning a dataset.  \n",
        "These methods can be grouped into three main categories:\n",
        "\n",
        "1. **Handling Duplicates**  \n",
        "   - `duplicated` ‚Üí detects duplicate rows.  \n",
        "   - `drop_duplicates` ‚Üí removes duplicate rows.  \n",
        "\n",
        "2. **Modifying Elements in a DataFrame**  \n",
        "   - `replace` ‚Üí replaces specific values.  \n",
        "   - `rename` ‚Üí renames columns or indexes.  \n",
        "   - `astype` ‚Üí changes the data type of columns.  \n",
        "\n",
        "3. **Operations on DataFrame Values**  \n",
        "   - `apply` ‚Üí applies a function to rows or columns.  \n",
        "   - `lambda` ‚Üí allows writing small anonymous functions for transformations.  \n"
      ],
      "metadata": {
        "id": "BVuC1fzDTLFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Duplicates (methods `duplicated` and `drop_duplicates`)\n",
        "\n",
        "Duplicates are identical rows that appear multiple times in a dataset.  \n",
        "\n",
        "üëâ When working with new data, it‚Äôs very important to **check for duplicates early on**.  \n",
        "The presence of duplicates can generate errors in statistical calculations or when plotting graphs.  \n",
        "\n",
        "---\n",
        "\n",
        "üìä Example DataFrame:\n",
        "\n",
        "| Name   | Age | Gender | Height |\n",
        "|--------|-----|--------|--------|\n",
        "| Robert | 56  | M      | 174    |\n",
        "| Mark   | 23  | M      | 182    |\n",
        "| Alina  | 32  | F      | 169    |\n",
        "| Mark   | 23  | M      | 182    |\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ To check for duplicates, we use the **`duplicated`** method:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Name\": [\"Robert\", \"Mark\", \"Alina\", \"Mark\"],\n",
        "    \"Age\": [56, 23, 32, 23],\n",
        "    \"Gender\": [\"M\", \"M\", \"F\", \"M\"],\n",
        "    \"Height\": [174, 182, 169, 182]\n",
        "})\n",
        "\n",
        "# Check for duplicates\n",
        "df.duplicated()\n",
        ">>>\n",
        "False\n",
        "False\n",
        "False\n",
        "True\n",
        "```\n",
        "\n",
        "## üìå Understanding the `duplicated()` method\n",
        "\n",
        "The **`duplicated()`** method returns a **Pandas Series** (similar to a column of a DataFrame).  \n",
        "It tells us for each row whether it is a duplicate (`True`) or not (`False`).  \n",
        "\n",
        "üëâ In our example, the result of `duplicated()` indicates that row with index **3** is a duplicate,  \n",
        "meaning it is an exact copy of a previous row (in this case, row **1**).\n",
        "\n",
        "---\n",
        "\n",
        "Since `duplicated()` returns a **Series**, we can apply the **`.sum()`** method to count the total number of duplicates.\n",
        "\n",
        "```python\n",
        "# Identify duplicates\n",
        "print(df.duplicated())\n",
        "\n",
        "# Count total number of duplicates\n",
        "print(\"Number of duplicates:\", df.duplicated().sum())\n",
        ">>> 1\n",
        "```\n",
        "\n",
        "## üßπ Removing duplicates with `drop_duplicates()`\n",
        "\n",
        "The method of a DataFrame used to **remove duplicates** is `drop_duplicates`.\n",
        "\n",
        "Its syntax is as follows:\n",
        "\n",
        "```python\n",
        "DataFrame.drop_duplicates(subset=None, keep='first', inplace=False)\n",
        "```\n",
        "- **subset** : column label or sequence of labels  \n",
        "  ‚Üí Allows you to specify which columns should be checked for duplicates.  \n",
        "  ‚Üí By default, all columns are considered.  \n",
        "\n",
        "- **keep** : {'first', 'last', False}, default `'first'`  \n",
        "  ‚Üí `'first'`: keeps the first occurrence and removes the others.  \n",
        "  ‚Üí `'last'`: keeps the last occurrence and removes the others.  \n",
        "  ‚Üí `False`: removes *all* duplicates.  \n",
        "\n",
        "- **inplace** : bool, default `False`  \n",
        "  ‚Üí If `True`, modifies the DataFrame directly without returning a new one.  \n",
        "  ‚Üí If `False`, returns a new DataFrame with duplicates removed.\n",
        "\n",
        "‚ö†Ô∏è **Warning** Be very careful when using the `inplace` parameter.  \n",
        "\n",
        "A **good practice** is to **avoid** using `inplace=True` and instead assign the DataFrame returned by the method to a new variable.  \n",
        "This way, you won‚Äôt accidentally overwrite your original data and you‚Äôll keep better control over your transformations."
      ],
      "metadata": {
        "id": "_G2W2T_0aPEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Creating a DataFrame from a Dictionary**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) How many duplicates are there in the `transactions` DataFrame?  \n",
        "- (b) Remove duplicates from the dataset while keeping only the **first occurrence**.  \n",
        "- (c) Using the parameters `subset` and `keep` of the method `drop_duplicates` on `transactions`, display the most recent transaction for each `prod_cat_code`."
      ],
      "metadata": {
        "id": "4qiOIluRpzcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "jI47fLYZq2qi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifying DataFrame Elements (methods `replace`, `rename`, and `astype`)\n",
        "\n",
        "The `replace` method allows you to substitute one or multiple values in a DataFrame column.\n",
        "\n",
        "Method Signature\n",
        "\n",
        "```python\n",
        "replace(to_replace, value, ...)\n",
        "```\n",
        "\n",
        "- `to_replace`: The value or list of values to be replaced.\n",
        "‚Üí Can be integers, strings, booleans, etc.\n",
        "\n",
        "- `value`: The replacement value or list of values.\n",
        "‚Üí Can also be integers, strings, booleans, etc.\n",
        "\n",
        "üí° This method is very useful when you need to clean or standardize categorical variables in your dataset.\n",
        "\n",
        "**df**\n",
        "\n",
        "|   Name   |  Country  | Age |\n",
        "|----------|-----------|-----|\n",
        "| 'Brown'  | Australia | 33  |\n",
        "| 'Dupont' | France    | 25  |\n",
        "| 'Anna'   | Japan     | 54  |\n",
        "\n",
        "**df_new**\n",
        "\n",
        "|   Name   |  Country  | Age |\n",
        "|----------|-----------|-----|\n",
        "| 'Brown'  | AUS       | 33  |\n",
        "| 'Dupont' | FRA       | 25  |\n",
        "| 'Anna'   | JPN       | 54  |\n",
        "\n",
        "```python\n",
        "df_new = df.replace(to_replace=['Australia','France','Japan'], value=['AUS','FRA','JPN'])\n",
        "```\n",
        "\n",
        "## Renaming Columns in a DataFrame\n",
        "\n",
        "In addition to modifying the elements of a DataFrame, you can also rename its columns.\n",
        "\n",
        "This is done using the rename method, which takes a dictionary as an argument: the keys are the old column names and the values are the new column names.\n",
        "\n",
        "You should also specify axis=1 (or columns=) to indicate that you are renaming columns and not rows.\n",
        "\n",
        "```python\n",
        "# Example DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Brown', 'Dupont', 'Anna'],\n",
        "    'Country': ['Australia', 'France', 'Japan'],\n",
        "    'Age': [33, 25, 54]\n",
        "})\n",
        "\n",
        "# Renaming columns\n",
        "df_renamed = df.rename(columns={'Name': 'Full_Name', 'Country': 'Nation', 'Age': 'Years'})\n",
        "\n",
        "df_renamed\n",
        "```\n",
        "\n",
        "## Changing Column Types with astype\n",
        "\n",
        "Sometimes, it is necessary to change not only the name of a column but also its type.\n",
        "\n",
        "For example, when importing a dataset, a variable might be interpreted as a string (str) while it is actually numeric. This can happen if even a single entry is misread.\n",
        "\n",
        "In pandas, you can change column types using the astype method.\n",
        "\n",
        "Common types you will use:\n",
        "\n",
        "- str : String ('Hello')\n",
        "- float : Floating-point number (1.0, 3.1415)\n",
        "- int : Integer (1, 1234)\n",
        "\n",
        "astype can take a dictionary where the keys are column names and the values are the new types. This is convenient when changing multiple columns at once.\n",
        "\n",
        "Most of the time, you will select a single column and overwrite it with its new type:\n",
        "\n",
        "```python\n",
        "# Method 1: Create a dictionary and apply astype to the entire DataFrame\n",
        "type_dict = {'col_1': 'int',\n",
        "             'col_2': 'float'}\n",
        "df = df.astype(type_dict)\n",
        "\n",
        "# Method 2: Select a single column and apply astype to the Series\n",
        "df['col_1'] = df['col_1'].astype('int')\n",
        "```\n",
        "\n",
        "‚úÖ Explanation:\n",
        "\n",
        "- Method 1 is useful when you want to change the type of multiple columns at once.\n",
        "- Method 2 is handy when you need to change the type of a single column.\n",
        "\n",
        "Both methods ensure that the column(s) have the correct type for calculations or further data manipulation."
      ],
      "metadata": {
        "id": "8g08UEmMtixT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
        "\n",
        "# Remove duplicates\n",
        "transactions = transactions.drop_duplicates(keep = 'first')"
      ],
      "metadata": {
        "id": "Hjx91OUpa1PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Cleaning and Modifying Columns**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Import the numpy module as np.\n",
        "\n",
        "- (b) Replace the values ['e-Shop', 'TeleShop', 'MBR', 'Flagship store', np.nan] in the column Store_type with [1, 2, 3, 4, 0]. At the same time, replace any missing values (np.nan) in the column prod_subcat_code with 0.\n",
        "\n",
        "- (c) Convert the columns Store_type and prod_subcat_code to type int.\n",
        "\n",
        "- (d) Rename the columns Store_type, Qty, Rate, and Tax to store_type, qty, rate, and tax."
      ],
      "metadata": {
        "id": "g2x6ouM--3wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "uYpP_pvf_U9I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operations on DataFrame values (apply method and lambda functions)\n",
        "\n",
        "It is often useful to modify or aggregate the information contained in the columns of a DataFrame using an operation or a function.\n",
        "\n",
        "These operations can be any type of function that takes a column as input.  \n",
        "\n",
        "The method used to apply an operation on a column is the **apply** method of a DataFrame, whose header is:\n",
        "\n",
        "```python\n",
        "apply(func, axis, ...)\n",
        "```\n",
        "### Where:\n",
        "\n",
        "- **func** is the function to apply on the column.  \n",
        "- **axis** specifies the dimension on which the operation should be applied.  \n",
        "\n",
        "### Example: `apply` with `np.sum`\n",
        "\n",
        "Suppose we want to compute the **sum of all rows** for each numerical column.  \n",
        "The `sum` function from NumPy performs this operation, which makes it perfect to use with the `apply` method.  \n",
        "\n",
        "Since the operation must be performed **on rows**, we need to specify the argument `axis=0` in the `apply` method.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"A\": [1, 2, 3],\n",
        "    \"B\": [10, 20, 30],\n",
        "    \"C\": [100, 200, 300]\n",
        "})\n",
        "\n",
        "# Apply np.sum on each column\n",
        "df_columns = df.apply(np.sum, axis=0)\n",
        ">>>\n",
        "```\n",
        "Result :\n",
        "|     |     |\n",
        "|-----|-----|\n",
        "| 'A' | 6   |\n",
        "| 'B' | 60  |\n",
        "| 'C' | 600 |\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"A\": [1, 2, 3],\n",
        "    \"B\": [10, 20, 30],\n",
        "    \"C\": [100, 200, 300]\n",
        "})\n",
        "\n",
        "# Apply np.sum on each column\n",
        "df_columns = df.apply(np.sum, axis=1)\n",
        ">>>\n",
        "```\n",
        "Result :\n",
        "|     |     |\n",
        "|-----|-----|\n",
        "| 'A' | 111 |\n",
        "| 'B' | 222 |\n",
        "| 'C' | 333 |"
      ],
      "metadata": {
        "id": "z9zyLQNgBq-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The column tran_date in the transactions DataFrame contains the transaction dates in the format day/month/year (e.g., '28/02/2014').\n",
        "\n",
        "Currently, these dates are stored as strings, which means we cannot directly perform calculations or statistical operations on them.\n",
        "\n",
        "üëâ A better approach would be to split this information into three separate columns: day, month, and year.\n",
        "This would allow us, for instance, to analyze seasonal trends or detect changes in customer behavior over time.\n",
        "\n",
        "For example, the date string '28/02/2014' is separated by the / character:\n",
        "\n",
        "```python\n",
        "date = '28/02/2014'\n",
        "date.split('/')\n",
        ">>> ['28', '02', '2014']\n",
        "```\n",
        "\n",
        "The split method returns a list containing the parts of the string separated by the chosen character.\n",
        "\n",
        "From here:\n",
        "- The day is the first element (parts[0])\n",
        "- The month is the second element (parts[1])\n",
        "- The year is the third element (parts[2])"
      ],
      "metadata": {
        "id": "4coecifyschh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Splitting Dates into Day, Month, and Year**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "- (a) Define a function get_day that takes a string as input and returns the first element after splitting it on '/'.\n",
        "\n",
        "- (b) Define the functions get_month and get_year that return the second and third elements of the split respectively.\n",
        "\n",
        "- (c) Store the results of applying these functions to the tran_date column in three variables: days, months, and years. Since these functions work element by element, you do not need to specify the axis argument in the apply method.\n",
        "\n",
        "- (d) Create the columns 'day', 'month', and 'year' in the DataFrame and assign them the values of days, months, and years. A new column can be created simply by declaring it."
      ],
      "metadata": {
        "id": "Li4tVZ-NuUvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "JIxT_b5wr9OD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The apply method becomes even more powerful when combined with a lambda function.\n",
        "\n",
        "In Python, the keyword lambda is used to define an anonymous function ‚Äî that is, a function without a name.\n",
        "\n",
        "A lambda function can take any number of arguments, but it must contain only one expression.\n",
        "\n",
        "The syntax\n",
        "```python\n",
        "lambda arguments: expression\n",
        "```\n",
        "Lambda functions allow us to define operations with a very compact syntax.\n",
        "\n",
        "They are particularly useful when the operation is simple and we don‚Äôt want to define a separate function with `def`.\n",
        "\n",
        "```python\n",
        "# Standard function\n",
        "def square(x):\n",
        "    return x**2\n",
        "\n",
        "# Equivalent with lambda\n",
        "square_lambda = lambda x: x**2\n",
        "\n",
        "print(square(4))        # Output: 16\n",
        "print(square_lambda(4)) # Output: 16\n",
        "```\n",
        "Thus, the previous exercise (extracting the day, month, and year from `tran_date`) can be written in a much more compact way using lambda functions inside `apply`.\n",
        "\n",
        "```python\n",
        "# Extract day, month, year using lambda inside apply\n",
        "transactions['day'] = transactions['tran_date'].apply(lambda x: x.split('/')[0])\n",
        "transactions['month'] = transactions['tran_date'].apply(lambda x: x.split('/')[1])\n",
        "transactions['year'] = transactions['tran_date'].apply(lambda x: x.split('/')[2])\n",
        "\n",
        "# Display the updated DataFrame\n",
        "transactions[['tran_date', 'day', 'month', 'year']].head()\n",
        "```\n",
        "---\n",
        "The column `prod_subcat_code` in transactions depends on the column `prod_cat_code` since it represents a subcategory of a product.\n",
        "\n",
        "It would make more sense to combine both category and subcategory into a single variable.\n",
        "\n",
        "Steps:\n",
        "- Convert both columns into strings using the method astype(str).\n",
        "- Concatenate them to create a unique code representing both the category and subcategory.\n",
        "\n",
        "üìå Example with string concatenation:\n",
        "\n",
        "```python\n",
        "string1 = \"I think\"\n",
        "string2 = \"therefore I am.\"\n",
        "\n",
        "# Concatenate the two strings with a space\n",
        "print(string1 + \" \" + string2)\n",
        "# >>> I think therefore I am.\n",
        "```\n",
        "\n",
        "To apply a function row by row, you must set `axis = 1` inside the `apply` method.\n",
        "\n",
        "Inside the function itself, each column can be accessed like a key in a DataFrame row.\n",
        "\n",
        "üëâ Example: computing the unit price of a product:\n",
        "\n",
        "```python\n",
        "transactions.apply(lambda row: row['total_amt'] / row['qty'], axis=1)\n",
        "```"
      ],
      "metadata": {
        "id": "T5MPOomswu0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Splitting Dates into Day, Month, and Year**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Using a **lambda function** applied on the **transactions** DataFrame, create a new column prod_cat containing the concatenation of `prod_cat_code` and `prod_subcat_code` separated by a hyphen `'-'`.\n",
        "Make sure to **convert both values** to strings before concatenating."
      ],
      "metadata": {
        "id": "0ax47Mrs03Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "Xy1NfKZXyEMi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Handling Missing Values**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "oNUj8PTAHotf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **missing value** can be either:  \n",
        "\n",
        "- A value that was not provided.  \n",
        "- A value that does not exist, often resulting from mathematical operations with no solution (e.g., division by zero).  \n",
        "\n",
        "In a DataFrame, missing values appear as **NaN** (\"Not a Number\").  \n",
        "\n",
        "In this section, we will explore several methods to:  \n",
        "\n",
        "- **Detect missing values** using `isna` and `any`.  \n",
        "- **Replace missing values** using `fillna`.  \n",
        "- **Remove missing values** using `dropna`.  \n",
        "\n",
        "In a previous exercise, we used the `replace` method on `transactions` to replace missing values with `0`.  \n",
        "This approach is **not rigorous** and should generally be avoided in practice.  \n",
        "\n",
        "For this reason, we will re-import the raw version of the `transactions` DataFrame to undo the transformations we applied in the previous exercises.\n",
        "\n",
        "Run the following cell to **re-import** the `transactions` dataset, **remove duplicates**, and **rename columns**:"
      ],
      "metadata": {
        "id": "BbaGq1ZmCAb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "transactions = pd.read_csv(\"transactions.csv\", sep=',', index_col=\"transaction_id\")\n",
        "\n",
        "# Remove duplicate rows\n",
        "transactions = transactions.drop_duplicates(keep='first')\n",
        "\n",
        "# Rename columns\n",
        "new_names = {\n",
        "    'Store_type': 'store_type',\n",
        "    'Qty': 'qty',\n",
        "    'Rate': 'rate',\n",
        "    'Tax': 'tax'\n",
        "}\n",
        "\n",
        "transactions = transactions.rename(new_names, axis=1)\n",
        "\n",
        "transactions.head()"
      ],
      "metadata": {
        "id": "Ti06ZVLJEZkO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting Missing Values (isna and any methods)\n",
        "\n",
        "The `isna` method of a DataFrame detects missing values. This method does not take any arguments.\n",
        "\n",
        "It returns a DataFrame of the same shape with:\n",
        "\n",
        "- `True` if the cell contains a missing value (`np.nan`).\n",
        "- `False` otherwise.\n",
        "\n",
        "Since `isna` returns a DataFrame, we can combine it with other DataFrame methods to get more detailed information:\n",
        "\n",
        "- The `any` method with the `axis` argument can determine which **columns** (`axis=0`) or **rows** (`axis=1`) contain at least one missing value.\n",
        "- The `sum` method counts the number of missing values per column or row (using the `axis` argument). Other statistical methods like `mean`, `max`, `argmax`, etc., can also be applied.\n",
        "\n",
        "Example using the previous DataFrame `df`:\n",
        "\n",
        "| Name     | Country    | Age |\n",
        "|----------|------------|-----|\n",
        "| NaN      | Australia  | NaN |\n",
        "| Duchamp  | France     | 25  |\n",
        "| Hana     | Japan      | 54  |\n",
        "\n",
        "Running `df.isna()` returns:\n",
        "\n",
        "| Name  | Country | Age   |\n",
        "|-------|---------|-------|\n",
        "| True  | False   | True  |\n",
        "| False | False   | False |\n",
        "| False | False   | False |\n",
        "\n",
        "```python\n",
        "# Example: Detecting missing values in a DataFrame\n",
        "\n",
        "# Detect COLUMNS that contain at least one missing value\n",
        "df.isna().any(axis=0)\n",
        "\n",
        "# Output:\n",
        "# Nom      True\n",
        "# Pays     False\n",
        "# Age      True\n",
        "\n",
        "# Detect ROWS that contain at least one missing value\n",
        "df.isna().any(axis=1)\n",
        "\n",
        "# Output:\n",
        "# 0     True\n",
        "# 1    False\n",
        "# 2    False\n",
        "\n",
        "# Use conditional indexing to display rows with at least one missing value\n",
        "df[df.isna().any(axis=1)]\n",
        ">>>\n",
        "```\n",
        "| Name  | Country   |  Age  |\n",
        "|-------|-----------|-------|\n",
        "| NaN   | Australia |   NaN |\n",
        "\n",
        "```python\n",
        "# Count missing values per COLUMN\n",
        "df.isnull().sum(axis=0)  # isnull and isna are equivalent\n",
        ">>>\n",
        "Name    1\n",
        "Country 0\n",
        "Age     1\n",
        "\n",
        "# Count missing values per ROW\n",
        "df.isnull().sum(axis=1)\n",
        ">>>\n",
        "0  2\n",
        "1  0\n",
        "2  0\n",
        "```\n"
      ],
      "metadata": {
        "id": "NuqzaCOY4RKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Handling Missing Values in a DataFrame**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) How many columns in the transactions DataFrame contain missing values?\n",
        "- (b) How many rows in transactions contain at least one missing value? You can use the `any` method combined with `sum`.\n",
        "- (c) Which column in transactions has the highest number of missing values?\n",
        "- (d) Display the rows in transactions that have at least one missing value in the columns 'rate', 'tax', and 'total_amt'. What do you observe?"
      ],
      "metadata": {
        "id": "y3DGgDABFG6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "U8_dgQI8FYkg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replacement of missing values (`fillna` method)\n",
        "\n",
        "The `fillna` method allows you to replace missing values (NaN) in a DataFrame with a value of your choice. This is useful to clean the dataset before analysis or statistical calculations.\n",
        "\n",
        "For example, we can replace missing values in a numeric column with 0, or in a categorical column with a default category.\n",
        "\n",
        "```python\n",
        "# Replace all NaN values in the DataFrame with zeros\n",
        "df.fillna(0)\n",
        "\n",
        "# Replace NaN values in each numeric column with the column mean\n",
        "df.fillna(df.mean())  # df.mean() can be replaced by any other statistical method\n",
        "```\n",
        "\n",
        "It is common to replace missing values in a numeric column with statistics such as:\n",
        "\n",
        "- Mean: `mean`\n",
        "- Median: `median`\n",
        "- Minimum/Maximum: `min`/`max`\n",
        "\n",
        "For categorical columns, missing values are usually replaced with:\n",
        "\n",
        "- Mode, i.e., the most frequent category: `mode`\n",
        "- A constant or arbitrary category: 0, -1\n",
        "\n",
        "To avoid mistakes when replacing missing values, it is strongly recommended to select the correct columns before using `fillna`.\n",
        "\n",
        "If you make mistakes in the following exercise, you can re-import the `transactions` DataFrame using the next cell."
      ],
      "metadata": {
        "id": "eWuV8fzCGqUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "transactions = pd.read_csv(\"transactions.csv\", sep=',', index_col=\"transaction_id\")\n",
        "\n",
        "# Remove duplicate rows\n",
        "transactions = transactions.drop_duplicates(keep='first')\n",
        "\n",
        "# Rename columns\n",
        "new_names = {\n",
        "    'Store_type': 'store_type',\n",
        "    'Qty': 'qty',\n",
        "    'Rate': 'rate',\n",
        "    'Tax': 'tax'\n",
        "}\n",
        "\n",
        "transactions = transactions.rename(new_names, axis=1)"
      ],
      "metadata": {
        "id": "0cLKrkXiHUOs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Replacing Missing Values in a DataFrame**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "- (a) Replace the missing values in the column `prod_subcat_code` of `transactions` with -1.\n",
        "\n",
        "- (b) Determine the most frequent category (mode) of the column `store_type` in `transactions`.\n",
        "\n",
        "- (c) Replace the missing values in the column `store_type` with this mode. You can access the mode value at index 0 of the Series returned by `mode`.\n",
        "\n",
        "- (d) Verify that the columns `prod_subcat_code` and `store_type` in `transactions` no longer contain any missing values."
      ],
      "metadata": {
        "id": "j8R-Cx2VCf-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "tEpAID8ECZln"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suppression of Missing Values (dropna method)¬∂\n",
        "\n",
        "The `dropna` method allows you to remove rows or columns that contain missing values.\n",
        "\n",
        "The method signature is as follows: `dropna(axis, how, subset, ..)`\n",
        "\n",
        "- **axis** specifies whether to remove rows or columns (0 for rows, 1 for columns).\n",
        "\n",
        "- **how** specifies the condition for removal:\n",
        "    - `how='any'`: remove the row (or column) if it contains at least one missing value.\n",
        "    - `how='all'`: remove the row (or column) only if all values are missing.\n",
        "\n",
        "- **subset** specifies which columns/rows to consider when checking for missing values.\n",
        "\n",
        "```python\n",
        "# Remove all rows that contain at least one missing value\n",
        "df = df.dropna(axis=0, how='any')\n",
        "\n",
        "# Remove columns that are completely empty\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Remove rows where all values are missing in the specific columns 'col2', 'col3', and 'col4'\n",
        "df = df.dropna(axis=0, how='all', subset=['col2','col3','col4'])\n",
        "```\n"
      ],
      "metadata": {
        "id": "z8edxml2jROA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Removing Missing Values**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "Some transactions for which the transaction amount is not provided are not relevant. For this reason:\n",
        "\n",
        "- (a) Remove the entries in the `transactions` DataFrame where the columns `rate`, `tax`, and `total_amt` are simultaneously empty.\n",
        "\n",
        "- (b) Verify that the columns in `transactions` no longer contain any missing values."
      ],
      "metadata": {
        "id": "_hjhWsFrCcXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "iBR2LerGESka"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Conclusion and Summary**\n",
        "\n",
        "</center>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "haPfgDjdcQxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter, we covered the essential `pandas` methods for cleaning a dataset and handling missing values (`NaN`).\n",
        "\n",
        "Preparing a dataset is always the first step in any data project.\n",
        "\n",
        "- **Data Cleaning**:\n",
        "  - Detect and remove duplicates in a `DataFrame` using `duplicated` and `drop_duplicates`.\n",
        "  - Modify DataFrame values and their types using `replace`, `rename`, and `astype`.\n",
        "  - Apply a function to a DataFrame using `apply` and `lambda` expressions.\n",
        "- **Handling Missing Values**:\n",
        "  - Detect them using `isna()` with `any()` and `sum()`.\n",
        "  - Replace them using `fillna()` and statistical functions.\n",
        "  - Remove them using `dropna()`.\n",
        "\n",
        "In the next notebook, you will explore more advanced `DataFrame` manipulations for deeper data analysis.\n",
        "\n",
        "In practice, datasets are rarely perfectly clean: missing values, duplicates, or inconsistent entries are common.  \n",
        "In the next section, we will learn how to clean and preprocess datasets using pandas, a crucial step before any meaningful analysis.\n"
      ],
      "metadata": {
        "id": "-2FIhAlWcMNw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvPOnXghLEag"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}