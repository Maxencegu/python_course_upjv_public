{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "# **Python for Data Science**\n",
        "\n",
        "### *Data Processing*\n",
        "\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "6UqIO5ZN7hD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Introduction**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8QLZXk-K9WUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing can be summarized in 4 essential operations: **filtering, joining, ordering, and grouping**.\n",
        "\n",
        "The **DataFrame** structure has become the standard in data manipulation because in most cases, it is enough to repeat or combine these four operations.\n",
        "\n",
        "In this exercise, you will learn how to use these 4 data preprocessing methods.\n",
        "\n",
        "Before starting this notebook, run the following cell in order to retrieve the work done in the previous notebooks.\n",
        "\n"
      ],
      "metadata": {
        "id": "PXA6UO-w8G2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Import ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Import the dataset\n",
        "transactions = pd.read_csv(\"transactions.csv\", sep=';', index_col=\"transaction_id\")\n",
        "\n",
        "# Remove duplicates\n",
        "transactions = transactions.drop_duplicates(keep='first')\n",
        "\n",
        "# Rename columns\n",
        "new_names = {'Store_type': 'store_type',\n",
        "             'Qty': 'qty',\n",
        "             'Rate': 'rate',\n",
        "             'Tax': 'tax'}\n",
        "\n",
        "transactions = transactions.rename(new_names, axis=1)\n",
        "\n",
        "### Handling Missing Values (NAs) ###\n",
        "\n",
        "# Replace NaNs in 'prod_subcat_code' with -1\n",
        "transactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1).astype(\"int\")\n",
        "\n",
        "# Get the mode of 'store_type'\n",
        "store_type_mode = transactions['store_type'].mode()\n",
        "\n",
        "# Replace NaNs in 'store_type' with its mode\n",
        "transactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n",
        "\n",
        "# Drop rows where 'rate', 'tax', and 'total_amt' are all missing\n",
        "transactions = transactions.dropna(axis=0, how='all', subset=['rate', 'tax', 'total_amt'])"
      ],
      "metadata": {
        "id": "djJlvXzjeZuV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Filtering a DataFrame with binary operators**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Wx72rTsmSgJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering consists of selecting a subset of rows from a DataFrame that satisfy a condition.  \n",
        "This is what we previously called *conditional indexing*, but the term *filtering* is the most commonly used in database management.  \n",
        "\n",
        "We cannot use the logical operators `and` and `or` when filtering with multiple conditions.  \n",
        "These operators create ambiguity that **pandas** cannot handle when filtering rows.  \n",
        "\n",
        "The operators adapted to filtering with multiple conditions are the **binary operators**:\n",
        "\n",
        "- The 'and' operator: `&`  \n",
        "- The 'or' operator: `|`  \n",
        "- The 'not' operator: `~`  \n",
        "\n",
        "These operators are similar to logical operators, but their evaluation methods are not the same.  \n",
        "\n",
        "---\n",
        "\n",
        "### The 'and' operator: `&`\n",
        "\n",
        "The `&` operator is used to filter a DataFrame with multiple conditions that must all be satisfied simultaneously.  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Let‚Äôs consider the following DataFrame `df` containing information about apartments in Paris:\n",
        "\n",
        "| neighborhood       | year | surface |\n",
        "|--------------------|------|---------|\n",
        "| 'Champs-Elys√©es'   | 1979 | 70      |\n",
        "| 'Europe'           | 1850 | 110     |\n",
        "| 'P√®re-Lachaise'    | 1935 | 55      |\n",
        "| 'Bercy'            | 1991 | 30      |\n",
        "\n",
        "If we want to find an apartment built in **1979** and with a surface greater than **60 m¬≤**, we can filter the rows of `df` with the following code:\n",
        "\n",
        "```python\n",
        "# Filtering the DataFrame with the 2 previous conditions\n",
        "print(df[(df['year'] == 1979) & (df['surface'] > 60)])\n",
        "\n",
        ">>>       neighborhood   year  surface\n",
        ">>> 0   Champs-Elys√©es  1979       70\n",
        "```\n",
        "The conditions must be enclosed in parentheses to avoid ambiguity in the order of evaluation.  \n",
        "Indeed, if the conditions are not properly separated, we will get the following error:\n",
        "\n",
        "```python\n",
        "print(df[df['year'] == 1979 & df['surface'] > 60])\n",
        "\n",
        ">>> ValueError: The truth value of a Series is ambiguous.\n",
        ">>> Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
        "```\n",
        "\n",
        "### The 'or' operator: `|`\n",
        "\n",
        "The `|` operator is used to filter a DataFrame with multiple conditions where at least one must be satisfied.  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Let‚Äôs consider the same DataFrame `df`:  \n",
        "\n",
        "| neighborhood       | year | surface (m¬≤) |\n",
        "|--------------------|------|--------------|\n",
        "| 'Champs-Elys√©es'   | 1979 | 70           |\n",
        "| 'Europe'           | 1850 | 110          |\n",
        "| 'P√®re-Lachaise'    | 1935 | 55           |\n",
        "| 'Bercy'            | 1991 | 30           |\n",
        "\n",
        "If we want to find an apartment built **after 1900** or located in the **P√®re-Lachaise** neighborhood, we can filter the rows of `df` with the following code:\n",
        "\n",
        "```python\n",
        "# Filtering the DataFrame with the 2 previous conditions\n",
        "print(df[(df['year'] > 1900) | (df['neighborhood'] == 'P√®re-Lachaise')])\n",
        "\n",
        ">>>     neighborhood    year  surface\n",
        ">>> 0  Champs-Elys√©es   1979       70\n",
        ">>> 2  P√®re-Lachaise    1935       55\n",
        ">>> 3           Bercy   1991       30\n",
        "````\n",
        "\n",
        "### The 'not' operator: `~`\n",
        "\n",
        "The `~` operator is used to filter a DataFrame on a condition whose **negation** must be satisfied.  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Let‚Äôs consider the same DataFrame `df`:  \n",
        "\n",
        "| neighborhood       | year | surface (m¬≤) |\n",
        "|--------------------|------|--------------|\n",
        "| 'Champs-Elys√©es'   | 1979 | 70           |\n",
        "| 'Europe'           | 1850 | 110          |\n",
        "| 'P√®re-Lachaise'    | 1935 | 55           |\n",
        "| 'Bercy'            | 1991 | 30           |\n",
        "\n",
        "If we want an apartment that is **not located in the Bercy neighborhood**, we can filter `df` as follows:\n",
        "\n",
        "```python\n",
        "# Filtering the DataFrame to exclude the Bercy neighborhood\n",
        "print(df[~(df['neighborhood'] == 'Bercy')])\n",
        "\n",
        ">>>     neighborhood    year  surface\n",
        ">>> 0  Champs-Elys√©es   1979       70\n",
        ">>> 1          Europe   1850      110\n",
        ">>> 2  P√®re-Lachaise    1935       55\n",
        "```"
      ],
      "metadata": {
        "id": "BVuC1fzDTLFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Filtering with conditions**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Display the first 5 rows of the DataFrame `transactions`.  \n",
        "- (b) From `transactions`, create a DataFrame named `e_shop` containing only the transactions made in stores of type `'e-Shop'` with a total amount greater than 5000 (columns: `store_type` and `total_amt`).  \n",
        "- (c) Similarly, create a DataFrame named `teleshop` containing the transactions made in stores of type `'TeleShop'` with a total amount greater than 5000.  \n",
        "- (d) Which of the two store types has the highest number of transactions greater than ‚Ç¨5000?"
      ],
      "metadata": {
        "id": "fEXlJNHPhSsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "iNk__Zohhs9S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Handling Missing Values**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Import the data from the files `'customer.csv'` and `'prod_cat_info.csv'` into two DataFrames named `customer` and `prod_cat_info`, respectively.  \n",
        "\n",
        "- (b) The columns `Gender` and `city_code` in `customer` each contain two missing values. Replace them with their mode using the `fillna` and `mode` methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "wV6pqhCFnXxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "ErdfKoEhn7Ef"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining DataFrames with `concat`\n",
        "\n",
        "The `concat` function from the **pandas** module allows you to concatenate multiple DataFrames, i.e., to stack them **vertically** or **horizontally**.  \n",
        "\n",
        "The function signature is as follows: `pandas.concat(objs, axis=...)`  \n",
        "\n",
        "- The `objs` parameter contains the list of DataFrames to concatenate.  \n",
        "- The `axis` parameter specifies whether to concatenate **vertically** (`axis=0`) or **horizontally** (`axis=1`).  \n",
        "\n",
        "When the number of rows or columns in the DataFrames does not match, the `concat` function fills the missing cells with `NaN`, as illustrated below."
      ],
      "metadata": {
        "id": "_G2W2T_0aPEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Concatenating DataFrames**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Split the variables (columns) of the `transactions` DataFrame into two, with half of the columns in a DataFrame named `part_1` and the other half in a DataFrame named `part_2`.  \n",
        "- (b) Reconstruct `transactions` in a DataFrame named `union` by concatenating `part_1` and `part_2`.  \n",
        "- (c) What happens if we concatenate `part_1` and `part_2` using the argument `axis=0`?"
      ],
      "metadata": {
        "id": "4qiOIluRpzcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "jI47fLYZq2qi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging DataFrames with the `merge` method\n",
        "\n",
        "Two DataFrames can be merged if they have a column in common.  \n",
        "This is done using the `merge` method of a DataFrame, which has the following signature:\n",
        "\n",
        "`merge(right, on, how, ...)`\n",
        "\n",
        "- The `right` parameter is the DataFrame to merge with the calling DataFrame.  \n",
        "- The `on` parameter is the name of the columns in the DataFrames that will serve as the reference for the merge. These columns must exist in both DataFrames.  \n",
        "- The `how` parameter specifies the type of join to perform for merging the DataFrames. Its values are based on SQL join syntax.  \n",
        "\n",
        "The `how` parameter can take 4 values (`'inner'`, `'outer'`, `'left'`, `'right'`), illustrated with the following two DataFrames `Persons` and `Vehicle`:\n",
        "\n",
        "**Persons**\n",
        "\n",
        "| Name     | Car        |\n",
        "|----------|------------|\n",
        "| Lila     | Twingo     |\n",
        "| Tiago    | Clio       |\n",
        "| Berenice | C4 Cactus  |\n",
        "| Joseph   | Twingo     |\n",
        "| Kader    | Swift      |\n",
        "| Romy     | Scenic     |\n",
        "\n",
        "**Vehicle**\n",
        "\n",
        "| Car       | Price  |\n",
        "|-----------|--------|\n",
        "| Twingo    | 11000  |\n",
        "| Swift     | 14500  |\n",
        "| C4 Cactus | 23000  |\n",
        "| Clio      | 16000  |\n",
        "| Prius     | 30000  |\n",
        "\n",
        "- `'inner'`: This is the default value of `how`. An inner join returns only the rows where the values in the common columns exist in both DataFrames. This type of join is often discouraged because it can lead to many missing entries. However, an inner join produces **no NaNs**.  \n",
        "\n",
        "    Example: `Persons.merge(right=Vehicle, on='Car', how='inner')`  \n",
        "\n",
        "- `'outer'`: An outer join merges all rows from both DataFrames. No row is removed. This method can generate a lot of NaNs.  \n",
        "\n",
        "    Example: `Persons.merge(right=Vehicle, on='Car', how='outer')`  \n",
        "\n",
        "- `'left'`: A left join returns all rows from the left DataFrame, and fills them with matching rows from the right DataFrame based on the common column.  \n",
        "\n",
        "    Example: `Persons.merge(right=Vehicle, on='Car', how='left')`  \n",
        "\n",
        "- `'right'`: A right join returns all rows from the right DataFrame, and fills them with matching rows from the left DataFrame based on the common column.  \n",
        "\n",
        "    Example: `Persons.merge(right=Vehicle, on='Car', how='right')`  \n",
        "\n",
        "Performing a left join, right join, or outer join followed by `dropna(how='any')` is equivalent to an inner join."
      ],
      "metadata": {
        "id": "8g08UEmMtixT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Merging transactions with customer data**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "The `customer` DataFrame contains information about clients corresponding to the `'cust_id'` column in `transactions`.  \n",
        "\n",
        "The `'customer_Id'` column in the `customer` DataFrame will allow us to join `transactions` and `customer`.  \n",
        "This will enrich the `transactions` dataset with additional information.  \n",
        "\n",
        "- (a) Using the `rename` method and a dictionary, rename the `'customer_Id'` column in the `customer` DataFrame to `'cust_id'`.  \n",
        "- (b) Using the `merge` method, perform a **left join** between `transactions` and `customer` on the `'cust_id'` column. Name the resulting DataFrame `fusion`.  \n",
        "- (c) Did the merge produce any `NaN` values?  \n",
        "- (d) Display the first rows of `fusion`. What are the new columns?"
      ],
      "metadata": {
        "id": "g2x6ouM--3wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "uYpP_pvf_U9I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resetting and Setting the Index of a DataFrame\n",
        "\n",
        "The merge was successful and did not produce any NaNs. However, the index of the resulting DataFrame is no longer the `'transaction_id'` column and has been reset to the default index (0, 1, 2, ...).  \n",
        "\n",
        "It is possible to **redefine the index** of a DataFrame using the `set_index` method.  \n",
        "\n",
        "This method can take as an argument:\n",
        "\n",
        "- The name of a column to use as the index.  \n",
        "- A Numpy array or a pandas Series with the same number of rows as the calling DataFrame.  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Let `df` be the following DataFrame:\n",
        "\n",
        "| Name     | Car        |\n",
        "|----------|------------|\n",
        "| Lila     | Twingo     |\n",
        "| Tiago    | Clio       |\n",
        "| Berenice | C4 Cactus  |\n",
        "| Joseph   | Twingo     |\n",
        "| Kader    | Swift      |\n",
        "| Romy     | Scenic     |\n",
        "\n",
        "We can set the `'Name'` column as the new index:\n",
        "\n",
        "```python\n",
        "df = df.set_index('Name')\n",
        "```\n",
        "\n",
        "This will produce the following DataFrame:\n",
        "\n",
        "| Name     | Car        |\n",
        "|----------|------------|\n",
        "| Lila     | Twingo     |\n",
        "| Tiago    | Clio       |\n",
        "| Berenice | C4 Cactus  |\n",
        "| Joseph   | Twingo     |\n",
        "| Kader    | Swift      |\n",
        "| Romy     | Scenic     |\n",
        "\n",
        "We can also set the index using a Numpy array, a Series, etc.\n",
        "\n",
        "```python\n",
        "# New index to use\n",
        "new_index = ['10000' + str(i) for i in range(6)]\n",
        "print(new_index)\n",
        ">>> ['100000', '100001', '100002', '100003', '100004', '100005']\n",
        "\n",
        "# Using a Numpy array or a Series is equivalent\n",
        "index_array = np.array(new_index)\n",
        "index_series = pd.Series(new_index)\n",
        "\n",
        "df = df.set_index(index_array)\n",
        "df = df.set_index(index_series)\n",
        "```\n",
        "\n",
        "This will produce the following DataFrame:\n",
        "\n",
        "|       | Name     | Car        |\n",
        "|-------|----------|------------|\n",
        "| 100000| Lila     | Twingo     |\n",
        "| 100001| Tiago    | Clio       |\n",
        "| 100002| Berenice | C4 Cactus  |\n",
        "| 100003| Joseph   | Twingo     |\n",
        "| 100004| Kader    | Swift      |\n",
        "| 100005| Romy     | Scenic     |\n",
        "\n",
        "To return to the default numeric indexing, use the `reset_index` method of the DataFrame:\n",
        "\n",
        "```python\n",
        "df = df.reset_index()\n",
        "```\n",
        "\n",
        "The previous index is not deleted. A new column will be created containing the old index:\n",
        "\n",
        "|       | index    |   Name     |   Car     |\n",
        "|-------|----------|------------|-----------|\n",
        "| 0     | 100000   | Lila       | Twingo    |\n",
        "| 1     | 100001   | Tiago      | Clio      |\n",
        "| 2     | 100002   | Berenice   | C4 Cactus |\n",
        "| 3     | 100003   | Joseph     | Twingo    |\n",
        "| 4     | 100004   | Kader      | Swift     |\n",
        "| 5     | 100005   | Romy       | Scenic    |\n"
      ],
      "metadata": {
        "id": "z9zyLQNgBq-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Restoring the index after merging**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "The merge between `transactions` and `customer` removed the index of `transactions`.  \n",
        "\n",
        "The index of a DataFrame can be retrieved using its `.index` attribute.  \n",
        "\n",
        "- (a) Retrieve the index of `transactions` and use it to set the index of `fusion`."
      ],
      "metadata": {
        "id": "Li4tVZ-NuUvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "JIxT_b5wr9OD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting a DataFrame: `sort_values` and `sort_index` methods\n",
        "\n",
        "The `sort_values` method allows you to sort the rows of a DataFrame based on the values of one or more columns.  \n",
        "\n",
        "The method signature is: `sort_values(by, ascending, ...)`\n",
        "\n",
        "- The `by` parameter specifies the column(s) to sort by.  \n",
        "- The `ascending` parameter is a boolean (`True` or `False`) that determines whether the sort is ascending or descending. By default, it is `True`.  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Consider the following DataFrame `df` describing students:\n",
        "\n",
        "| FirstName | Grade | BonusPoints |\n",
        "|-----------|-------|-------------|\n",
        "| 'Amelie'  | A     | 1           |\n",
        "| 'Marin'   | F     | 1           |\n",
        "| 'Pierre'  | A     | 2           |\n",
        "| 'Zoe'     | C     | 1           |\n",
        "\n",
        "First, we will sort by a single column, for example the `'BonusPoints'` column:\n",
        "\n",
        "```python\n",
        "# Sort the DataFrame df by the 'BonusPoints' column\n",
        "df_sorted = df.sort_values(by='BonusPoints', ascending=True)\n",
        "```\n",
        "The result will be as follows:\n",
        "\n",
        "| FirstName | Grade | BonusPoints |\n",
        "|-----------|-------|-------------|\n",
        "| 'Amelie'  | A     | 1           |\n",
        "| 'Marin'   | F     | 1           |\n",
        "| 'Zoe'     | C     | 1           |\n",
        "| 'Pierre'  | A     | 2           |\n",
        "\n",
        "The rows of the `df_sorted` DataFrame are thus sorted in ascending order of the `'Points bonus'` column.  \n",
        "However, if we look at the `'Note'` column, we notice that it is not sorted alphabetically for the rows that have the same `'Points bonus'` value.  \n",
        "\n",
        "We can fix this by also sorting by the `'Note'` column:\n",
        "\n",
        "```python\n",
        "# Sort the DataFrame df by 'Points bonus', and in case of ties, by 'Note'\n",
        "df_sorted = df.sort_values(by=['Points bonus', 'Note'], ascending=True)\n",
        "```\n",
        "The result will be as follows:\n",
        "\n",
        "The `sort_index` method allows you to sort a DataFrame based on its index.  \n",
        "When the index is the default numeric index, this method is not very useful.  \n",
        "It is therefore often combined with the `set_index` method of pandas, as we saw earlier.  \n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "# Set the 'Grade' column as the index of df\n",
        "df = df.set_index('Grade')\n",
        "\n",
        "# Sort the DataFrame df by its index\n",
        "df = df.sort_index()\n",
        "```\n",
        "\n",
        "This produces the following DataFrame:\n",
        "\n",
        "| Grade | FirstName | BonusPoints |\n",
        "|-------|-----------|-------------|\n",
        "| A     | 'Amelie'  | 1           |\n",
        "| A     | 'Pierre'  | 2           |\n",
        "| C     | 'Zoe'     | 1           |\n",
        "| F     | 'Marin'   | 1           |\n",
        "\n",
        "Consider the following two DataFrames containing boat rental data.  \n",
        "\n",
        "**Boats DataFrame (`bateaux`):**\n",
        "\n",
        "| BoatName   | Color  | ReservationNumber | NumberOfReservations |\n",
        "|------------|--------|-----------------|--------------------|\n",
        "| Julia      | blue   | 2               | 34                 |\n",
        "| Siren      | green  | 3               | 10                 |\n",
        "| Sea Sons   | red    | 6               | 20                 |\n",
        "| Hercules   | blue   | 1               | 41                 |\n",
        "| Cesar      | yellow | 4               | 12                 |\n",
        "| Minerva    | green  | 5               | 16                 |\n",
        "\n",
        "**Clients DataFrame (`clients`):**\n",
        "\n",
        "| ClientID | ClientName | ReservationID |\n",
        "|----------|------------|---------------|\n",
        "| 91       | Marie      | 1             |\n",
        "| 154      | Anna       | 2             |\n",
        "| 124      | Yann       | 3             |\n",
        "| 320      | Lea        | 7             |\n",
        "| 87       | Marc       | 9             |\n",
        "| 22       | Yassine    | 10            |\n",
        "\n"
      ],
      "metadata": {
        "id": "T5MPOomswu0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the following cell to create these DataFrames.\n",
        "# Define the dictionaries\n",
        "data_boats = {\n",
        "    'BoatName': ['Julia', 'Siren', 'Sea Sons', 'Hercules', 'Cesar', 'Minerva'],\n",
        "    'Color': ['blue', 'green', 'red', 'blue', 'yellow', 'green'],\n",
        "    'ReservationNumber': [2, 3, 6, 1, 4, 5],\n",
        "    'NumberOfReservations': [34, 10, 20, 41, 12, 16]\n",
        "}\n",
        "\n",
        "data_clients = {\n",
        "    'ClientID': [91, 154, 124, 320, 87, 22],\n",
        "    'ClientName': ['Marie', 'Anna', 'Yann', 'Lea', 'Marc', 'Yassine'],\n",
        "    'ReservationID': [1, 2, 3, 7, 9, 10]\n",
        "}\n",
        "\n",
        "# Create the DataFrames\n",
        "boats = pd.DataFrame(data_boats)\n",
        "clients = pd.DataFrame(data_clients)"
      ],
      "metadata": {
        "id": "9uHpRgo58HN1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Joining boat and client data**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "We want to easily determine which client reserved the boats in the `boats` DataFrame.  \n",
        "To do this, we just need to merge the DataFrames.  \n",
        "\n",
        "- (a) Rename the `'ReservationNumber'` column in `boats` to `'ReservationID'` using the `rename` method.  \n",
        "- (b) In a DataFrame named `boats_clients`, perform a **left join** between `boats` and `clients`.  \n",
        "- (c) Set the `'BoatName'` column as the index of the `boats_clients` DataFrame.  \n",
        "- (d) Using the `loc` method, which allows indexing a DataFrame, find out who reserved the boats `'Julia'` and `'Siren'`.  \n",
        "- (e) Using the `isna` method applied to the `'ClientName'` column, determine which boats have not been reserved.  \n",
        "- (f) The number of times a boat has been reserved so far is given in the `'NumberOfReservations'` column.  \n",
        "Using the `sort_values` method, determine the name of the client who reserved the **blue boat** with the highest number of reservations."
      ],
      "metadata": {
        "id": "0ax47Mrs03Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "Xy1NfKZXyEMi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping elements of a DataFrame: `groupby`, `agg`, and `crosstab` methods\n",
        "\n",
        "The `groupby` method allows you to group the rows of a DataFrame that share a common value in a column.  \n",
        "\n",
        "This method does **not** return a DataFrame.  \n",
        "The object returned by `groupby` is of class `DataFrameGroupBy`.  \n",
        "\n",
        "This class allows operations such as computing statistics (sum, mean, max, etc.) for each category of the column used for grouping.  \n",
        "\n",
        "The general structure of a `groupby` operation is as follows:\n",
        "\n",
        "1. Split the data (Split).  \n",
        "2. Apply a function (Apply).  \n",
        "3. Combine the results (Combine).  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Assume that the boats in the `boats` DataFrame are all identical and have the same age.  \n",
        "We want to determine if the color of a boat influences its number of reservations.  \n",
        "To do this, we will calculate the average number of reservations per boat for each color:\n",
        "\n",
        "- Split the boats by color.  \n",
        "- Compute the average number of reservations (`mean`).  \n",
        "- Combine the results into a DataFrame for easy comparison.  \n",
        "\n",
        "We can use `groupby` followed by `mean` to obtain the result.  \n",
        "\n",
        "All common statistical methods (`count`, `mean`, `max`, etc.) can be used after `groupby`.  \n",
        "They will only apply to columns with compatible types.  \n",
        "\n",
        "It is also possible to specify for each column which function should be applied in the \"Apply\" step of a `groupby` operation.  \n",
        "To do this, use the `agg` method of the `DataFrameGroupBy` object, providing a dictionary where each key is a column name and the value is the function to apply.\n",
        "\n",
        "**Example:**  \n",
        "\n",
        "Consider the `transactions` DataFrame:\n",
        "\n",
        "| transaction_id | cust_id | tran_date  | prod_subcat_code | prod_cat_code | qty  | rate  | tax    | total_amt | store_type |\n",
        "|----------------|---------|-----------|-----------------|---------------|------|-------|--------|-----------|------------|\n",
        "| 80712190438    | 270351  | 28-02-14  | 1               | 1             | -5   | -772  | 405.3  | -4265.3   | e-Shop     |\n",
        "| 29258453508    | 270384  | 27-02-14  | 5               | 3             | -5   | -1497 | 785.925| -8270.92  | e-Shop     |\n",
        "| 51750724947    | 273420  | 24-02-14  | 6               | 5             | -2   | -791  | 166.11 | -1748.11  | TeleShop   |\n",
        "| 93274880719    | 271509  | 24-02-14  | 11              | 6             | -3   | -1363 | 429.345| -4518.35  | e-Shop     |\n",
        "| 51750724947    | 273420  | 23-02-14  | 6               | 5             | -2   | -791  | 166.11 | -1748.11  | TeleShop   |\n",
        "\n",
        "We want, for each client (`cust_id`):\n",
        "\n",
        "- For the `total_amt` column: minimum, maximum, and total amount spent.  \n",
        "- For the `store_type` column: the number of different store types in which the client made a transaction.  \n",
        "\n",
        "We can perform these calculations using a `groupby` operation:\n",
        "\n",
        "1. Split transactions by client ID.  \n",
        "2. For `total_amt`, compute `min`, `max`, and `sum`. For `store_type`, count the number of unique categories.  \n",
        "3. Combine the results into a DataFrame.\n",
        "\n",
        "To find the number of unique categories for `store_type`, we can use the following lambda function:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "n_modalities = lambda store_type: len(np.unique(store_type))\n",
        "```\n",
        "\n",
        "- The lambda function must take a column as an argument and return a number.  \n",
        "- The function `np.unique` determines the unique values present in a sequence.  \n",
        "- The function `len` counts the number of elements in a sequence.  \n",
        "\n",
        "Thus, this function allows us to determine the number of unique categories for the `store_type` column.  \n",
        "\n",
        "To apply these functions in a `groupby` operation, we use a dictionary where the keys are the columns to process and the values are the functions to apply.\n",
        "\n",
        "```python\n",
        "functions_to_apply = {\n",
        "    # Standard statistical methods can be specified as strings\n",
        "    'total_amt': ['min', 'max', 'sum'],\n",
        "    'store_type': n_modalities\n",
        "}\n",
        "```\n",
        "\n",
        "This dictionary can now be used with the `agg` method:\n",
        "\n",
        "```python\n",
        "transactions.groupby('cust_id').agg(functions_to_apply)\n",
        "```\n",
        "\n",
        "This produces the following `DataFrameGroupBy`:\n",
        "\n",
        "            total_amount          store_type\n",
        "| cust_id | min      | max     | sum     | lambda  |\n",
        "|---------|----------|---------|---------|---------|\n",
        "| 266783  | -5838.82 | 5838.82 | 3113.89 |   2     |\n",
        "| 266784  | 442      | 4279.66 | 5694.07 |   3     |\n",
        "| 266785  | -6828.9  | 6911.77 | 21613.8 |   3     |\n",
        "| 266788  | 1312.74  | 1927.12 | 6092.97 |   3     |\n",
        "| 266794  | -135.915 | 4610.06 | 27981.9 |   4     |\n",
        "           \n"
      ],
      "metadata": {
        "id": "khxz6t5oRtBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: Grouping by client to analyze quantities**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Using a `groupby` operation, determine for each client, based on the quantity of items purchased in a transaction (`qty` column):\n",
        "\n",
        "  - The maximum quantity.  \n",
        "  - The minimum quantity.  \n",
        "  - The median quantity.  \n",
        "\n",
        "  You should filter the transactions to keep only those with positive quantities.  \n",
        "  To do this, you can use conditional indexing (`qty[qty > 0]`) within a lambda function."
      ],
      "metadata": {
        "id": "d6Vk7-ORCdk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "Ti06ZVLJEZkO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to group and summarize data is to use the `crosstab` function from pandas, which, as its name suggests, is used to cross-tabulate columns of a DataFrame.  \n",
        "\n",
        "It allows you to visualize the frequency of occurrence of pairs of categories in a DataFrame.  \n",
        "\n",
        "**Example:**  \n",
        "\n",
        "In the `transactions` DataFrame, we want to know which category and sub-category pairs are the most frequent (columns `prod_cat_code` and `prod_subcat_code`).  \n",
        "\n",
        "The pandas `crosstab` function can be used as follows:\n",
        "\n",
        "```python\n",
        "colonne1 = transactions['prod_cat_code']\n",
        "colonne2 = transactions['prod_subcat_code']\n",
        "pd.crosstab(colonne1, colonne2)\n",
        "```\n",
        "\n",
        "This command produces the following DataFrame:\n",
        "\n",
        "prod_subcat_code\n",
        "\n",
        "| prod_cat_code | -1 | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  | 11  | 12  |\n",
        "|---------------|----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
        "| 1             | 4  | 1001| 0   | 981 | 958 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
        "| 2             | 4  | 934 | 0   | 1040|1005 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
        "| 3             | 11 | 0   | 0   | 0   |1020 | 950 | 0   | 0   | 966 | 976 | 945 | 0   | 0   |\n",
        "| 4             | 5  | 993 | 0   | 0   | 988 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n",
        "| 5             | 3  | 0   | 0   |1023 | 0   | 0   | 984 |1037 | 0   | 0   | 998 |1029 | 962 |\n",
        "| 6             | 5  | 0   |1002 | 0   | 0   | 0   | 0   | 0   | 0   | 0   |1025 |1013 |1057 |\n",
        "\n",
        "The cell (i, j) in the resulting DataFrame contains the number of elements in the DataFrame that have category i for the first column (`prod_cat_code`) and category j for the second column (`prod_subcat_code`).  \n",
        "\n",
        "Thus, it is easy to determine, for example, that the dominant sub-categories of category 4 are 1 and 4.  \n",
        "\n",
        "The `normalize` argument of `crosstab` allows you to display the frequencies as percentages.  \n",
        "For example, using `normalize=1` normalizes the table along axis 1, i.e., across each column:\n",
        "\n",
        "The cell (i, j) in the resulting DataFrame contains the number of elements that have category i for the first column (`prod_cat_code`) and category j for the second column (`prod_subcat_code`).  \n",
        "\n",
        "This makes it easy to see, for example, that the dominant sub-categories of category 4 are 1 and 4.  \n",
        "\n",
        "The `normalize` argument in `crosstab` allows displaying frequencies as percentages.  \n",
        "For example, `normalize=1` normalizes the table along **axis 1**, i.e., across each column:\n",
        "\n",
        "```python\n",
        "# Extract the year from the transaction date\n",
        "column1 = transactions['tran_date'].apply(lambda x: int(x.split('-')[2]))\n",
        "column2 = transactions['store_type']\n",
        "\n",
        "pd.crosstab(column1,\n",
        "            column2,\n",
        "            normalize=1)\n",
        "```\n",
        "\n",
        "This produces the following DataFrame:\n",
        "\n",
        "| tran_date | Flagship store | MBR     | TeleShop | e-Shop  |\n",
        "|-----------|----------------|--------|----------|---------|\n",
        "| 2011      | 0.291942       | 0.323173 | 0.283699 | 0.306947 |\n",
        "| 2012      | 0.331792       | 0.322093 | 0.336767 | 0.322886 |\n",
        "| 2013      | 0.335975       | 0.3115   | 0.332512 | 0.320194 |\n",
        "| 2014      | 0.0402906      | 0.0432339| 0.0470219| 0.0499731|\n",
        "\n",
        "This DataFrame allows us to say that 33.5975% of the transactions made in a 'Flagship store' occurred in 2013.  \n",
        "\n",
        "Conversely, by setting `normalize=0`, we normalize the table across **rows**:\n",
        "\n",
        "| tran_date | Flagship store | MBR     | TeleShop | e-Shop  |\n",
        "|-----------|----------------|--------|----------|---------|\n",
        "| 2011      | 0.191121       | 0.21548  | 0.182617 | 0.410781 |\n",
        "| 2012      | 0.20096        | 0.198693 | 0.20056  | 0.399787 |\n",
        "| 2013      | 0.205522       | 0.194074 | 0.2      | 0.400404 |\n",
        "| 2014      | 0.173132       | 0.189215 | 0.198675 | 0.438978 |\n",
        "\n",
        "Row-wise normalization allows us to deduce that transactions made in an 'e-Shop' account for 41.0781% of the transactions in 2011.  \n",
        "\n",
        "In the file `covid_tests.csv`, we have a dataset of 200 COVID-19 tests. The columns in this dataset are:\n",
        "\n",
        "- `patient_id`: ID of the tested patient.  \n",
        "- `test_result`: Result of the detection test. 1 if the patient tested positive, 0 otherwise.  \n",
        "- `infected`: 1 if the patient was actually infected, 0 otherwise.\n"
      ],
      "metadata": {
        "id": "NuqzaCOY4RKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "### **üîç Example: COVID-19 Test Analysis**\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "- (a) Load the dataset from the file `covid_tests.csv`. The separator is `;`.  \n",
        "- (b) Using the `pd.crosstab` function, determine the number of **False Negatives** produced by this test.  \n",
        "A false negative occurs when the test indicates that a patient is not infected, but they actually are.  \n",
        "- (c) What is the **False Positive rate** of the test?  \n",
        "The false positive rate corresponds to the proportion of false positives among all healthy individuals.  \n",
        "You will need to normalize the results to compute this."
      ],
      "metadata": {
        "id": "y3DGgDABFG6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "U8_dgQI8FYkg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "## **üìñ Conclusion and Summary**\n",
        "\n",
        "</center>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "haPfgDjdcQxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion and Recap\n",
        "\n",
        "In this notebook, you have learned how to:\n",
        "\n",
        "- **Filter rows of a DataFrame** with multiple conditions using the binary operators `&`, `|`, and `-`:\n",
        "\n",
        "  ```python\n",
        "  # Year equals 1979 and surface greater than 60\n",
        "  df[(df['annee'] == 1979) & (df['surface'] > 60)]\n",
        "\n",
        "  # Year greater than 1900 or district equals 'P√®re-Lachaise'\n",
        "  df[(df['ann√©e'] > 1900) | (df['quartier'] == 'P√®re-Lachaise')]\n",
        "  ```\n",
        "\n",
        "- **Merge DataFrames** using the `concat` function and the `merge` method:\n",
        "\n",
        "  ```python\n",
        "  # Vertical concatenation\n",
        "  pd.concat([df1, df2], axis=0)\n",
        "\n",
        "  # Horizontal concatenation\n",
        "  pd.concat([df1, df2], axis=1)\n",
        "\n",
        "  # Different types of joins\n",
        "  df1.merge(right=df2, on='column', how='inner')\n",
        "  df1.merge(right=df2, on='column', how='outer')\n",
        "  df1.merge(right=df2, on='column', how='left')\n",
        "  df1.merge(right=df2, on='column', how='right')\n",
        "  ```\n",
        "\n",
        "- **Sort and order the values of a DataFrame** using the methods `sort_values` and `sort_index`:\n",
        "\n",
        "  ```python\n",
        "  # Sort a DataFrame by the 'column' in ascending order\n",
        "  df.sort_values(by='column', ascending=True)\n",
        "  ```\n",
        "\n",
        "- **Perform a complex `groupby` operation** using lambda functions along with the `groupby` and `agg` methods:\n",
        "\n",
        "  ```python\n",
        "  functions_to_apply = {\n",
        "      'column1': ['min', 'max'],\n",
        "      'column2': [np.mean, np.std],\n",
        "      'column3': lambda x: x.max() - x.min()\n",
        "  }\n",
        "\n",
        "  df.groupby('column_to_group_by').agg(functions_to_apply)\n",
        "  ```"
      ],
      "metadata": {
        "id": "-2FIhAlWcMNw"
      }
    }
  ]
}